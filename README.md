# Exp-3-EXP3ELM-
Evaluation and Analysis of the Performance of the EXP3 Algorithm in Stochastic Environments

Multi Armed bandits are the simplest instance of the exploration-exploitation trade-off problem, which is the basic question in reinforcement learning.
Multi Armed bandits is a problem in which a fixed limited set of resources must be allocated between competing (alternative) choices in a way that maximizes their expected gain, when each choice's properties are only partially known at the time of allocation, and may become better understood as time passes or by allocating resources to the choice
In stochastic multi armed bandit problems the rewards for playing each arm are generated independently from unknown distributions corresponding to each arm.  In adversarial multi armed bandit problems a sequence of rewards is generated for each arm by an adversary before the game starts.

### Results

![image](https://github.com/s-brajendra/Exp-3-EXP3ELM-/assets/80635193/77298a69-2296-4b84-a4e9-50cae6dbffac)
